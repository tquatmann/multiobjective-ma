Storm 1.0.0

Command line arguments: --prism models/ma/jobs/jobs10_2.ma --prop models/ma/jobs/jobs4.csl --multiobjective:precision 0.001 -stats -tm 
Current working directory: /home/storm/Desktop

Time for model construction: 0.432s.

-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	12554
Transitions: 	34581
Choices: 	23061
Markovian St.: 	11531
Max. Rate.: 	5.7
Reward Models:  avg_waiting_time
Labels: 	5
   * deadlock -> 1 state(s)
   * all_jobs_finished -> 1 state(s)
   * half_of_jobs_finished -> 2772 state(s)
   * slowest_before_fastest -> 3073 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Time for model preprocessing: 0.000s.


Model checking property multi(R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"], Pmin=? [F "slowest_before_fastest"], Pmax=? [true U<=(10 / (2 * 2)) "all_jobs_finished"], Pmax=? [true U<=(10 / (4 * 2)) "half_of_jobs_finished"]) ...
Preprocessing done in 0.045s seconds.
 Result: 
---------------------------------------------------------------------------------------------------------------------------------------
                                                       Multi-objective Query                                              
---------------------------------------------------------------------------------------------------------------------------------------

Original Formula: 
--------------------------------------------------------------
	multi(R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"], Pmin=? [F "slowest_before_fastest"], Pmax=? [true U<=(10 / (2 * 2)) "all_jobs_finished"], Pmax=? [true U<=(10 / (4 * 2)) "half_of_jobs_finished"])

Objectives:
--------------------------------------------------------------
R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective1 (negative), 	time bounds: none)
Pmin=? [F "slowest_before_fastest"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective2 (negative), 	time bounds: none)
Pmax=? [true U<=(10 / (2 * 2)) "all_jobs_finished"] 	(toOrigVal:001*x +000, 	intern threshold:   none, 	intern reward model: objective3 (positive), 	time bounds:<=0000(10 / (2 * 2)))
Pmax=? [true U<=(10 / (4 * 2)) "half_of_jobs_finished"] 	(toOrigVal:001*x +000, 	intern threshold:   none, 	intern reward model: objective4 (positive), 	time bounds:<=0000(10 / (4 * 2)))
--------------------------------------------------------------

Original Model Information:
-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	12554
Transitions: 	34581
Choices: 	23061
Markovian St.: 	11531
Max. Rate.: 	5.7
Reward Models:  avg_waiting_time
Labels: 	5
   * deadlock -> 1 state(s)
   * all_jobs_finished -> 1 state(s)
   * half_of_jobs_finished -> 2772 state(s)
   * slowest_before_fastest -> 3073 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Preprocessed Model Information:
-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	14610
Transitions: 	39974
Choices: 	26662
Markovian St.: 	13332
Max. Rate.: 	5.7
Reward Models:  objective4, objective3, objective1, objective2
Labels: 	5
   * slowest_before_fastest -> 3073 state(s)
   * all_jobs_finished -> 2 state(s)
   * deadlock -> 2 state(s)
   * half_of_jobs_finished -> 3388 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

---------------------------------------------------------------------------------------------------------------------------------------


real	120m0.004s
user	119m56.452s
sys	0m2.008s
