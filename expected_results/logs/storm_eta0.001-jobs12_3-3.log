Storm 1.0.0

Command line arguments: --prism models/ma/jobs/jobs12_3.ma --prop models/ma/jobs/jobs3.csl --multiobjective:precision 0.001 -stats -tm 
Current working directory: /home/storm/Desktop

Time for model construction: 11.541s.

-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	116814
Transitions: 	450783
Choices: 	225437
Markovian St.: 	112719
Max. Rate.: 	8.5
Reward Models:  avg_waiting_time
Labels: 	5
   * deadlock -> 1 state(s)
   * all_jobs_finished -> 1 state(s)
   * half_of_jobs_finished -> 19404 state(s)
   * slowest_before_fastest -> 27915 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Time for model preprocessing: 0.000s.


Model checking property multi(T[exp]min=? [F "all_jobs_finished"], T[exp]min=? [F "half_of_jobs_finished"], R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"], Pmin=? [F "slowest_before_fastest"]) ...
Preprocessing done in 0.575s seconds.
 Result: 
---------------------------------------------------------------------------------------------------------------------------------------
                                                       Multi-objective Query                                              
---------------------------------------------------------------------------------------------------------------------------------------

Original Formula: 
--------------------------------------------------------------
	multi(T[exp]min=? [F "all_jobs_finished"], T[exp]min=? [F "half_of_jobs_finished"], R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"], Pmin=? [F "slowest_before_fastest"])

Objectives:
--------------------------------------------------------------
T[exp]min=? [F "all_jobs_finished"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective1 (negative), 	time bounds: none)
T[exp]min=? [F "half_of_jobs_finished"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective2 (negative), 	time bounds: none)
R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective3 (negative), 	time bounds: none)
Pmin=? [F "slowest_before_fastest"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective4 (negative), 	time bounds: none)
--------------------------------------------------------------

Original Model Information:
-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	116814
Transitions: 	450783
Choices: 	225437
Markovian St.: 	112719
Max. Rate.: 	8.5
Reward Models:  avg_waiting_time
Labels: 	5
   * deadlock -> 1 state(s)
   * all_jobs_finished -> 1 state(s)
   * half_of_jobs_finished -> 19404 state(s)
   * slowest_before_fastest -> 27915 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Preprocessed Model Information:
-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	133253
Transitions: 	512379
Choices: 	256268
Markovian St.: 	128135
Max. Rate.: 	8.5
Reward Models:  objective4, objective3, objective1, objective2
Labels: 	5
   * slowest_before_fastest -> 27915 state(s)
   * all_jobs_finished -> 2 state(s)
   * deadlock -> 2 state(s)
   * half_of_jobs_finished -> 23814 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

---------------------------------------------------------------------------------------------------------------------------------------


real	120m0.013s
user	119m53.596s
sys	0m5.016s
