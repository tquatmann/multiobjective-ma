Storm 1.0.0

Command line arguments: --prism models/ma/jobs/jobs12_3.ma --prop models/ma/jobs/jobs4.csl --multiobjective:precision 0.001 -stats -tm 
Current working directory: /home/storm/Desktop

Time for model construction: 11.503s.

-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	116814
Transitions: 	450783
Choices: 	225437
Markovian St.: 	112719
Max. Rate.: 	8.5
Reward Models:  avg_waiting_time
Labels: 	5
   * deadlock -> 1 state(s)
   * all_jobs_finished -> 1 state(s)
   * half_of_jobs_finished -> 19404 state(s)
   * slowest_before_fastest -> 27915 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Time for model preprocessing: 0.000s.


Model checking property multi(R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"], Pmin=? [F "slowest_before_fastest"], Pmax=? [true U<=(12 / (2 * 3)) "all_jobs_finished"], Pmax=? [true U<=(12 / (4 * 3)) "half_of_jobs_finished"]) ...
Preprocessing done in 0.447s seconds.
 Result: 
---------------------------------------------------------------------------------------------------------------------------------------
                                                       Multi-objective Query                                              
---------------------------------------------------------------------------------------------------------------------------------------

Original Formula: 
--------------------------------------------------------------
	multi(R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"], Pmin=? [F "slowest_before_fastest"], Pmax=? [true U<=(12 / (2 * 3)) "all_jobs_finished"], Pmax=? [true U<=(12 / (4 * 3)) "half_of_jobs_finished"])

Objectives:
--------------------------------------------------------------
R[exp]{"avg_waiting_time"}min=? [F "all_jobs_finished"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective1 (negative), 	time bounds: none)
Pmin=? [F "slowest_before_fastest"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective2 (negative), 	time bounds: none)
Pmax=? [true U<=(12 / (2 * 3)) "all_jobs_finished"] 	(toOrigVal:001*x +000, 	intern threshold:   none, 	intern reward model: objective3 (positive), 	time bounds:<=0000(12 / (2 * 3)))
Pmax=? [true U<=(12 / (4 * 3)) "half_of_jobs_finished"] 	(toOrigVal:001*x +000, 	intern threshold:   none, 	intern reward model: objective4 (positive), 	time bounds:<=0000(12 / (4 * 3)))
--------------------------------------------------------------

Original Model Information:
-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	116814
Transitions: 	450783
Choices: 	225437
Markovian St.: 	112719
Max. Rate.: 	8.5
Reward Models:  avg_waiting_time
Labels: 	5
   * deadlock -> 1 state(s)
   * all_jobs_finished -> 1 state(s)
   * half_of_jobs_finished -> 19404 state(s)
   * slowest_before_fastest -> 27915 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Preprocessed Model Information:
-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	133253
Transitions: 	512379
Choices: 	256268
Markovian St.: 	128135
Max. Rate.: 	8.5
Reward Models:  objective4, objective3, objective1, objective2
Labels: 	5
   * slowest_before_fastest -> 27915 state(s)
   * all_jobs_finished -> 2 state(s)
   * deadlock -> 2 state(s)
   * half_of_jobs_finished -> 23814 state(s)
   * init -> 1 state(s)
choice labels: 	no
-------------------------------------------------------------- 

---------------------------------------------------------------------------------------------------------------------------------------


real	120m0.006s
user	119m56.900s
sys	0m1.400s
