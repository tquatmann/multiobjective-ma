Storm 1.0.0

Command line arguments: --prism models/ma/polling/polling.ma --prop models/ma/polling/polling2.csl -const N=3,Q=2 --multiobjective:precision 0.01 -stats -tm 
Current working directory: /home/storm/Desktop

Time for model construction: 0.078s.

-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	1020
Transitions: 	2507
Choices: 	1867
Markovian St.: 	523
Max. Rate.: 	14
Reward Models:  queuesize1, processedjobs2, queuesize2, processedjobs1
Labels: 	4
   * init -> 1 state(s)
   * q2full -> 576 state(s)
   * deadlock -> 0 state(s)
   * q1full -> 576 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Time for model preprocessing: 0.000s.


Model checking property multi(R[exp]{"processedjobs1"}max=? [F "q1full"], R[exp]{"processedjobs2"}max=? [F "q2full"], R[exp]{"queuesize1"}min=? [F "q1full"], R[exp]{"queuesize2"}min=? [F "q2full"]) ...
Preprocessing done in 0.009s seconds.
 Result: 
---------------------------------------------------------------------------------------------------------------------------------------
                                                       Multi-objective Query                                              
---------------------------------------------------------------------------------------------------------------------------------------

Original Formula: 
--------------------------------------------------------------
	multi(R[exp]{"processedjobs1"}max=? [F "q1full"], R[exp]{"processedjobs2"}max=? [F "q2full"], R[exp]{"queuesize1"}min=? [F "q1full"], R[exp]{"queuesize2"}min=? [F "q2full"])

Objectives:
--------------------------------------------------------------
R[exp]{"processedjobs1"}max=? [F "q1full"] 	(toOrigVal:001*x +000, 	intern threshold:   none, 	intern reward model: objective1 (positive), 	time bounds: none)
R[exp]{"processedjobs2"}max=? [F "q2full"] 	(toOrigVal:001*x +000, 	intern threshold:   none, 	intern reward model: objective2 (positive), 	time bounds: none)
R[exp]{"queuesize1"}min=? [F "q1full"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective3 (negative), 	time bounds: none)
R[exp]{"queuesize2"}min=? [F "q2full"] 	(toOrigVal:0-1*x +000, 	intern threshold:   none, 	intern reward model: objective4 (negative), 	time bounds: none)
--------------------------------------------------------------

Original Model Information:
-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	1020
Transitions: 	2477
Choices: 	1852
Markovian St.: 	508
Max. Rate.: 	14
Reward Models:  queuesize1, processedjobs2, queuesize2, processedjobs1
Labels: 	4
   * init -> 1 state(s)
   * q2full -> 576 state(s)
   * deadlock -> 0 state(s)
   * q1full -> 576 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Preprocessed Model Information:
-------------------------------------------------------------- 
Model type: 	Markov Automaton (sparse)
States: 	1980
Transitions: 	5183
Choices: 	3853
Markovian St.: 	871
Max. Rate.: 	14
Reward Models:  objective4, objective2, objective3, objective1
Labels: 	4
   * q2full -> 828 state(s)
   * init -> 1 state(s)
   * q1full -> 828 state(s)
   * deadlock -> 0 state(s)
choice labels: 	no
-------------------------------------------------------------- 

---------------------------------------------------------------------------------------------------------------------------------------

Solving multi-objective query took 0.106s seconds (consisting of 0.009s seconds for preprocessing and 0.096s seconds for value iteration-based exploration of achievable points).
Result (initial states): 
Underapproximation of achievable values: Polytope with 12 Halfspaces:
   (         0,          1,          0,          0) * x <= 0.269025
   (         0,  0.0253311,         -1,          0) * x <= 0.00348136
   (         0,          0,          0,         -1) * x <= -0.002
   (         1, 2.87383e-05,          0,          0) * x <= 0.313577
   (4.25714e-09,  0.0253311,         -1,          0) * x <= 0.00348136
   (1.91254e-08,   0.113801,          0,         -1) * x <= 0.0286154
   (5.70216e-07,          1,          0,          0) * x <= 0.269025
   (         0,   0.113801,          0,         -1) * x <= 0.0286154
   (         0,          0,         -1,          0) * x <= -0.00333334
   (  0.926623,          1,          0,          0) * x <= 0.531574
   (         1,          0,          0,          0) * x <= 0.31357
   (  0.026921,          0,          0,         -1) * x <= 0.00644162

Overapproximation of achievable values: Polytope with 6 Halfspaces:
   (         1,          0,          0,          0) * x <= 0.31357
   (         0,          1,          0,          0) * x <= 0.269025
   (         0,          0,         -1,          0) * x <= -0.00333334
   (         0,          0,          0,         -1) * x <= -0.002
   (  0.192545,   0.807455,          0,          0) * x <= 0.271781
   (  0.535671,   0.464329,          0,          0) * x <= 0.279879

5 pareto optimal points found (Note that these points are safe, i.e., contained in the underapproximation, but there is no guarantee for optimality):
   (0.3135697979, 0.2341497067, 0.003333336793, 0.002000001198 )
   (0.1673170721, 0.2690252222, 0.003333337975, 0.002000001198 )
   (0.1673170721, 0.2690251755, 0.003333336793, 0.001999995888 )
   (0.3135696007, 0.2410129673, 0.003333336793, 0.001999995888 )
   (0.2833391982, 0.269025156, 0.003333336793, 0.001999995888 )


Time for model checking: 0.106s.

Performance statistics:
  * peak memory usage: 215MB
  * CPU time: 0.156s
  * wallclock time: 0.189s

real	0m0.205s
user	0m0.156s
sys	0m0.044s
