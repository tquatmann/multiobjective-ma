Storm 1.0.0

Command line arguments: --prism models/mdp/team/team2obj_3.nm --prop models/mdp/team/team2obj_3_pareto.pctl --multiobjective:precision 0.001 -tm -stats 
Current working directory: /home/storm/Desktop

Time for model construction: 0.203s.

-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	12475
Transitions: 	15228
Choices: 	14935
Reward Models:  w_1_total
Labels: 	3
   * init -> 1 state(s)
   * deadlock -> 0 state(s)
   * task1_compl -> 546 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Model checking property multi(Pmax=? [F "task1_compl"], R[exp]{"w_1_total"}max=? [C]) ...
Preprocessing done in 0.110s seconds.
 Result: 
---------------------------------------------------------------------------------------------------------------------------------------
                                                       Multi-objective Query                                              
---------------------------------------------------------------------------------------------------------------------------------------

Original Formula: 
--------------------------------------------------------------
	multi(Pmax=? [F "task1_compl"], R[exp]{"w_1_total"}max=? [C])

Objectives:
--------------------------------------------------------------
000000Pmax=? [F "task1_compl"] 	(toOrigVal:001*x +000, 	intern threshold:   none, 	intern reward model: objective1 (positive), 	time bounds: none)
00R[exp]{"w_1_total"}max=? [C] 	(toOrigVal:001*x +000, 	intern threshold:   none, 	intern reward model: objective2 (positive), 	time bounds: none)
--------------------------------------------------------------

Original Model Information:
-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	12475
Transitions: 	15228
Choices: 	14935
Reward Models:  w_1_total
Labels: 	3
   * init -> 1 state(s)
   * deadlock -> 0 state(s)
   * task1_compl -> 546 state(s)
choice labels: 	no
-------------------------------------------------------------- 

Preprocessed Model Information:
-------------------------------------------------------------- 
Model type: 	MDP (sparse)
States: 	12475
Transitions: 	15228
Choices: 	14935
Reward Models:  objective2, objective1
Labels: 	3
   * init -> 1 state(s)
   * task1_compl -> 546 state(s)
   * deadlock -> 0 state(s)
choice labels: 	no
-------------------------------------------------------------- 

---------------------------------------------------------------------------------------------------------------------------------------

 WARN (SparsePcaaQuery.cpp:120): Numerical issues: The overapproximation would not contain the underapproximation. Hence, a halfspace is shifted by 1.58882e-15.
Solving multi-objective query took 0.256s seconds (consisting of 0.110s seconds for preprocessing and 0.145s seconds for value iteration-based exploration of achievable points).
Result (initial states): 
Underapproximation of achievable values: Polytope with 5 Halfspaces:
   (         1,   0.722222) * x <= 2.48639
   (         1,        0.5) * x <= 2.0102
   (         0,          1) * x <= 2.32653
   (         1,          0) * x <= 1
   (         1,          1) * x <= 3.08163

Overapproximation of achievable values: Polytope with 6 Halfspaces:
   (         1,          0) * x <= 1
   (         0,          1) * x <= 2.32653
   (  0.535714,   0.464286) * x <= 1.49781
   (  0.473684,   0.526316) * x <= 1.58217
   (  0.666667,   0.333333) * x <= 1.34014
   (       0.5,        0.5) * x <= 1.54082

4 pareto optimal points found (Note that these points are safe, i.e., contained in the underapproximation, but there is no guarantee for optimality):
   (0.7551020408, 2.326530612 )
   (0000000001, 2.020408163 )
   (0.9387755102, 2.142857143 )
   (0.9387755102, 2.142857143 )


Time for model checking: 0.256s.

Performance statistics:
  * peak memory usage: 215MB
  * CPU time: 0.392s
  * wallclock time: 0.485s

real	0m0.505s
user	0m0.396s
sys	0m0.084s
